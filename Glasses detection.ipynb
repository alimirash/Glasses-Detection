{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015c4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np \n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b7fe1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Faces = []\n",
    "files_name = os.listdir('Faces/')\n",
    "for file_name in files_name:\n",
    "    file_name = 'Faces/' + file_name\n",
    "    face = np.array(Image.open(file_name)) \n",
    "    Faces.append(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9c5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for file_name in files_name:\n",
    "    if file_name.find('open')== -1:\n",
    "        label.append('sunglasses')\n",
    "    else:\n",
    "        label.append('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67abf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Faces = np.array(Faces)\n",
    "label = np.array(label)\n",
    "\n",
    "# The data of the training and test sets are divided 70 by 30\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Faces, label, test_size = 0.30, random_state = 1)\n",
    "\n",
    "nsamples, nx, ny = X_train.shape\n",
    "d2_train_dataset = X_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "d2_test_dataset = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8399f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.90327750\n",
      "Iteration 2, loss = 0.72850470\n",
      "Iteration 3, loss = 0.72315405\n",
      "Iteration 4, loss = 0.71708318\n",
      "Iteration 5, loss = 0.71169736\n",
      "Iteration 6, loss = 0.70628421\n",
      "Iteration 7, loss = 0.70219015\n",
      "Iteration 8, loss = 0.69906128\n",
      "Iteration 9, loss = 0.69597072\n",
      "Iteration 10, loss = 0.69423091\n",
      "Iteration 11, loss = 0.69338304\n",
      "Iteration 12, loss = 0.69265700\n",
      "Iteration 13, loss = 0.69265656\n",
      "Iteration 14, loss = 0.69242614\n",
      "Iteration 15, loss = 0.69248532\n",
      "Iteration 16, loss = 0.69262505\n",
      "Iteration 17, loss = 0.69272986\n",
      "Iteration 18, loss = 0.69270657\n",
      "Iteration 19, loss = 0.69268423\n",
      "Iteration 20, loss = 0.69267138\n",
      "Iteration 21, loss = 0.69261361\n",
      "Iteration 22, loss = 0.69253285\n",
      "Iteration 23, loss = 0.69242682\n",
      "Iteration 24, loss = 0.69262752\n",
      "Iteration 25, loss = 0.69263590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#Here we created 4 models, we set their maximum iteration to 110 and set verbose to Ture to reduce our loss in each iteration and set the learning rate to 0.01.\n",
    "# In model 1, the number of nodes (neurons) is 2 and the number of layers is 2\n",
    "model_1 = MLPClassifier(hidden_layer_sizes=(1,1) , max_iter = 110 ,random_state = 1\n",
    "                     ,verbose=True ,learning_rate_init =.01)\n",
    "\n",
    "model_1.fit(d2_train_dataset,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2b7897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518348623853211"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 1 for the training set\n",
    "model_1.score(d2_train_dataset,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c714469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4627659574468085"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 1 for the validation set\n",
    "y_pred = model_1.predict(d2_test_dataset)\n",
    "model_1.score(d2_test_dataset,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01414dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.95231090\n",
      "Iteration 2, loss = 1.20446019\n",
      "Iteration 3, loss = 1.17449839\n",
      "Iteration 4, loss = 1.14625720\n",
      "Iteration 5, loss = 1.11971474\n",
      "Iteration 6, loss = 1.09451173\n",
      "Iteration 7, loss = 1.06989092\n",
      "Iteration 8, loss = 1.04705957\n",
      "Iteration 9, loss = 1.02422985\n",
      "Iteration 10, loss = 1.00267560\n",
      "Iteration 11, loss = 0.98231060\n",
      "Iteration 12, loss = 0.96234061\n",
      "Iteration 13, loss = 0.94395227\n",
      "Iteration 14, loss = 0.92599906\n",
      "Iteration 15, loss = 0.90840639\n",
      "Iteration 16, loss = 0.89264313\n",
      "Iteration 17, loss = 0.87679367\n",
      "Iteration 18, loss = 0.86238618\n",
      "Iteration 19, loss = 0.84835590\n",
      "Iteration 20, loss = 0.83585507\n",
      "Iteration 21, loss = 0.82329420\n",
      "Iteration 22, loss = 0.81246486\n",
      "Iteration 23, loss = 0.80156694\n",
      "Iteration 24, loss = 0.79200083\n",
      "Iteration 25, loss = 0.78260864\n",
      "Iteration 26, loss = 0.77391888\n",
      "Iteration 27, loss = 0.76599930\n",
      "Iteration 28, loss = 0.75850490\n",
      "Iteration 29, loss = 0.75148486\n",
      "Iteration 30, loss = 0.74517652\n",
      "Iteration 31, loss = 0.73922919\n",
      "Iteration 32, loss = 0.73386846\n",
      "Iteration 33, loss = 0.72905815\n",
      "Iteration 34, loss = 0.72464910\n",
      "Iteration 35, loss = 0.72085723\n",
      "Iteration 36, loss = 0.71772473\n",
      "Iteration 37, loss = 0.71429134\n",
      "Iteration 38, loss = 0.71172783\n",
      "Iteration 39, loss = 0.70929224\n",
      "Iteration 40, loss = 0.70739122\n",
      "Iteration 41, loss = 0.70534395\n",
      "Iteration 42, loss = 0.70368026\n",
      "Iteration 43, loss = 0.70213981\n",
      "Iteration 44, loss = 0.70068143\n",
      "Iteration 45, loss = 0.69964930\n",
      "Iteration 46, loss = 0.69849207\n",
      "Iteration 47, loss = 0.69767976\n",
      "Iteration 48, loss = 0.69691110\n",
      "Iteration 49, loss = 0.69626112\n",
      "Iteration 50, loss = 0.69573518\n",
      "Iteration 51, loss = 0.69523087\n",
      "Iteration 52, loss = 0.69494738\n",
      "Iteration 53, loss = 0.69448455\n",
      "Iteration 54, loss = 0.69431629\n",
      "Iteration 55, loss = 0.69398069\n",
      "Iteration 56, loss = 0.69371135\n",
      "Iteration 57, loss = 0.69354846\n",
      "Iteration 58, loss = 0.69339926\n",
      "Iteration 59, loss = 0.69333384\n",
      "Iteration 60, loss = 0.69322703\n",
      "Iteration 61, loss = 0.69311845\n",
      "Iteration 62, loss = 0.69305038\n",
      "Iteration 63, loss = 0.69298172\n",
      "Iteration 64, loss = 0.69287407\n",
      "Iteration 65, loss = 0.69282293\n",
      "Iteration 66, loss = 0.69278823\n",
      "Iteration 67, loss = 0.69273344\n",
      "Iteration 68, loss = 0.69262121\n",
      "Iteration 69, loss = 0.69260547\n",
      "Iteration 70, loss = 0.69258589\n",
      "Iteration 71, loss = 0.69258265\n",
      "Iteration 72, loss = 0.69258984\n",
      "Iteration 73, loss = 0.69257284\n",
      "Iteration 74, loss = 0.69261325\n",
      "Iteration 75, loss = 0.69259926\n",
      "Iteration 76, loss = 0.69260574\n",
      "Iteration 77, loss = 0.69255785\n",
      "Iteration 78, loss = 0.69254765\n",
      "Iteration 79, loss = 0.69252226\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# In model 1, the number of nodes (neurons) is 4 and the number of layers is 2\n",
    "\n",
    "model_2 = MLPClassifier(hidden_layer_sizes=(2,2) , max_iter = 110 , alpha = 1e-4,random_state = 1\n",
    "                     ,verbose=True ,learning_rate_init =.01)\n",
    "model_2.fit(d2_train_dataset,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f585ed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518348623853211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 2 for the training set\n",
    "model_2.score(d2_train_dataset,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8ac509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4627659574468085"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 2 for the validation set\n",
    "y_pred = model_2.predict(d2_test_dataset)\n",
    "model_2.score(d2_test_dataset,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a53413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.82565212\n",
      "Iteration 2, loss = 0.78659484\n",
      "Iteration 3, loss = 0.80647639\n",
      "Iteration 4, loss = 0.80585031\n",
      "Iteration 5, loss = 0.80208404\n",
      "Iteration 6, loss = 0.79635422\n",
      "Iteration 7, loss = 0.78977922\n",
      "Iteration 8, loss = 0.78234592\n",
      "Iteration 9, loss = 0.77445827\n",
      "Iteration 10, loss = 0.76686921\n",
      "Iteration 11, loss = 0.75983736\n",
      "Iteration 12, loss = 0.75281732\n",
      "Iteration 13, loss = 0.74624960\n",
      "Iteration 14, loss = 0.74031859\n",
      "Iteration 15, loss = 0.73429752\n",
      "Iteration 16, loss = 0.72943465\n",
      "Iteration 17, loss = 0.72499206\n",
      "Iteration 18, loss = 0.72095032\n",
      "Iteration 19, loss = 0.71747438\n",
      "Iteration 20, loss = 0.71413259\n",
      "Iteration 21, loss = 0.71116006\n",
      "Iteration 22, loss = 0.70852049\n",
      "Iteration 23, loss = 0.70623785\n",
      "Iteration 24, loss = 0.70428893\n",
      "Iteration 25, loss = 0.70263535\n",
      "Iteration 26, loss = 0.70160817\n",
      "Iteration 27, loss = 0.70007516\n",
      "Iteration 28, loss = 0.69905589\n",
      "Iteration 29, loss = 0.69813496\n",
      "Iteration 30, loss = 0.69743251\n",
      "Iteration 31, loss = 0.69671132\n",
      "Iteration 32, loss = 0.69610565\n",
      "Iteration 33, loss = 0.69559890\n",
      "Iteration 34, loss = 0.69513260\n",
      "Iteration 35, loss = 0.69467663\n",
      "Iteration 36, loss = 0.69432126\n",
      "Iteration 37, loss = 0.69398382\n",
      "Iteration 38, loss = 0.69376530\n",
      "Iteration 39, loss = 0.69355253\n",
      "Iteration 40, loss = 0.69339127\n",
      "Iteration 41, loss = 0.69323560\n",
      "Iteration 42, loss = 0.69311730\n",
      "Iteration 43, loss = 0.69300910\n",
      "Iteration 44, loss = 0.69303520\n",
      "Iteration 45, loss = 0.69282289\n",
      "Iteration 46, loss = 0.69275817\n",
      "Iteration 47, loss = 0.69270779\n",
      "Iteration 48, loss = 0.69268778\n",
      "Iteration 49, loss = 0.69263912\n",
      "Iteration 50, loss = 0.69263790\n",
      "Iteration 51, loss = 0.69263957\n",
      "Iteration 52, loss = 0.69267168\n",
      "Iteration 53, loss = 0.69266292\n",
      "Iteration 54, loss = 0.69264513\n",
      "Iteration 55, loss = 0.69261628\n",
      "Iteration 56, loss = 0.69265062\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# In model 1, the number of nodes (neurons) is 10 and the number of layers is 2\n",
    "model_3 = MLPClassifier(hidden_layer_sizes=(5,5) , max_iter = 110 , alpha = 1e-4,random_state = 1\n",
    "                     ,verbose=True ,learning_rate_init =.01)\n",
    "model_3.fit(d2_train_dataset,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6402cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518348623853211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 3 for the training set\n",
    "model_3.score(d2_train_dataset,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b665f226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4627659574468085"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 3 for the validation set\n",
    "y_pred = model_3.predict(d2_test_dataset)\n",
    "model_3.score(d2_test_dataset,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b814e68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 16.61589007\n",
      "Iteration 2, loss = 13.57068366\n",
      "Iteration 3, loss = 3.15885242\n",
      "Iteration 4, loss = 4.58369742\n",
      "Iteration 5, loss = 2.13827278\n",
      "Iteration 6, loss = 2.46906234\n",
      "Iteration 7, loss = 3.08612850\n",
      "Iteration 8, loss = 1.89657060\n",
      "Iteration 9, loss = 2.17729164\n",
      "Iteration 10, loss = 2.94844314\n",
      "Iteration 11, loss = 2.03280721\n",
      "Iteration 12, loss = 1.90604641\n",
      "Iteration 13, loss = 2.07552859\n",
      "Iteration 14, loss = 1.09438219\n",
      "Iteration 15, loss = 0.77264307\n",
      "Iteration 16, loss = 0.77001069\n",
      "Iteration 17, loss = 0.93374218\n",
      "Iteration 18, loss = 0.84648999\n",
      "Iteration 19, loss = 0.57933688\n",
      "Iteration 20, loss = 0.43872222\n",
      "Iteration 21, loss = 0.66959482\n",
      "Iteration 22, loss = 0.50988804\n",
      "Iteration 23, loss = 0.51598265\n",
      "Iteration 24, loss = 0.40941859\n",
      "Iteration 25, loss = 0.43066086\n",
      "Iteration 26, loss = 0.39614919\n",
      "Iteration 27, loss = 0.43869197\n",
      "Iteration 28, loss = 0.41179090\n",
      "Iteration 29, loss = 0.43059713\n",
      "Iteration 30, loss = 0.44897975\n",
      "Iteration 31, loss = 0.46648397\n",
      "Iteration 32, loss = 0.43030014\n",
      "Iteration 33, loss = 0.40885450\n",
      "Iteration 34, loss = 0.40909327\n",
      "Iteration 35, loss = 0.39805783\n",
      "Iteration 36, loss = 0.46235068\n",
      "Iteration 37, loss = 0.29367463\n",
      "Iteration 38, loss = 0.31930539\n",
      "Iteration 39, loss = 0.34084679\n",
      "Iteration 40, loss = 0.29467971\n",
      "Iteration 41, loss = 0.27024940\n",
      "Iteration 42, loss = 0.26956193\n",
      "Iteration 43, loss = 0.24988451\n",
      "Iteration 44, loss = 0.27449379\n",
      "Iteration 45, loss = 0.25629699\n",
      "Iteration 46, loss = 0.24899775\n",
      "Iteration 47, loss = 0.23555166\n",
      "Iteration 48, loss = 0.24536609\n",
      "Iteration 49, loss = 0.25887108\n",
      "Iteration 50, loss = 0.24014108\n",
      "Iteration 51, loss = 0.30788615\n",
      "Iteration 52, loss = 0.29123843\n",
      "Iteration 53, loss = 0.35503883\n",
      "Iteration 54, loss = 0.34836992\n",
      "Iteration 55, loss = 0.22092089\n",
      "Iteration 56, loss = 0.22920925\n",
      "Iteration 57, loss = 0.22753317\n",
      "Iteration 58, loss = 0.34306357\n",
      "Iteration 59, loss = 0.50492389\n",
      "Iteration 60, loss = 1.05149639\n",
      "Iteration 61, loss = 0.82043451\n",
      "Iteration 62, loss = 0.43486357\n",
      "Iteration 63, loss = 0.67813206\n",
      "Iteration 64, loss = 0.79047708\n",
      "Iteration 65, loss = 0.56885730\n",
      "Iteration 66, loss = 0.64600026\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# In model 1, the number of nodes (neurons) is 50 and the number of layers is 2\n",
    "model_4 = MLPClassifier(hidden_layer_sizes=(17,17,17) , max_iter = 110 , alpha = 1e-4,random_state = 1\n",
    "                     ,verbose=True ,learning_rate_init =.01)\n",
    "model_4.fit(d2_train_dataset,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4491205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786697247706422"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 4 for the training set\n",
    "model_4.score(d2_train_dataset,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b91a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872340425531915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 4 for the validation set\n",
    "y_pred = model_4.predict(d2_test_dataset)\n",
    "model_4.score(d2_test_dataset,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the layer increases, the accuracy of the model gets better and better\n",
    "# In these models that we defined and fitted on our data set, model 4 brings us good accuracy due to the number of layers and the number of neurons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
